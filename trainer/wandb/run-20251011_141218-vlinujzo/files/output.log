LLM可训练总参数量：25.830 百万
Epoch:[1/5](0/120068) loss:6.813 lr:0.000000550000 epoch_Time:34180.0min:
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000018D9D8ADEE0>
Traceback (most recent call last):
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\site-packages\torch\utils\data\dataloader.py", line 1604, in __del__
    self._shutdown_workers()
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\site-packages\torch\utils\data\dataloader.py", line 1568, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\multiprocessing\process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\multiprocessing\popen_spawn_win32.py", line 112, in wait
    res = _winapi.WaitForSingleObject(int(self._handle), msecs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
Traceback (most recent call last):
  File "C:\codekg\dmxllmproject\minimindtrain\trainer\train_full_sft.py", line 203, in <module>
    train_epoch(epoch, wandb)
  File "C:\codekg\dmxllmproject\minimindtrain\trainer\train_full_sft.py", line 55, in train_epoch
    scaler.scale(loss).backward()
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\site-packages\torch\_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\site-packages\torch\autograd\__init__.py", line 347, in backward
    _engine_run_backward(
  File "C:\Users\ccf\.conda\envs\llmpytorch\Lib\site-packages\torch\autograd\graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
